{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc2hdd/home/ypeng455/.conda/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to \"AutoModelForCausalLM.from_pretrained\".\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [01:59<00:00, 11.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "peft_model_id = \"/hpc2hdd/home/ypeng455/Qwen-VL/output_qwen\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen-VL-Chat\", device_map=\"cuda\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "lora_model = PeftModel.from_pretrained(model,peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-VL-Chat\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我直接拿微信里边的聊天记录来rag 来自:Antigone,Antigone,wxid 4b07h7sg40oh12\n"
     ]
    }
   ],
   "source": [
    "query = tokenizer.from_list_format([\n",
    "    {'text': '0.0 有没有可能 直接拿一个人的社交资料，日记啥的来rag 不用对pretrain model训练 来自:张芮铭_dcai,章瑞明,wxid_klbotamaav4722'},\n",
    "])\n",
    "response, history = lora_model.chat(tokenizer, query=query, history=None,)#system=\"你是彭一洋,微信昵称为Antigone,大家也会称呼你为pyy,彭总，彭老师，下面你将要与张芮铭_dcai,章瑞明,wxid_klbotamaav4722进行一对一对话\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer to first person:我有点事 来自:Antigone,Antigone,wxid_4b07h7sg40oh12\n",
      "answer to second person:我今天没课 来自:Antigone,Antigone,wxid_4b07h7sg40oh12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1234)\n",
    "query = tokenizer.from_list_format([\n",
    "    {'text': '要出去吃饭吗 来自:张芮铭_dcai,章瑞明,wxid_klbotamaav4722'},\n",
    "])\n",
    "response, history = lora_model.chat(tokenizer, query=query, history=None ,system=\"你是彭一洋,微信昵称为Antigone,大家也会称呼你为pyy,彭总，彭老师，下面你将要与张芮铭_dcai,章瑞明,wxid_klbotamaav4722进行一对一对话\")\n",
    "print(f'answer to first person:{response}')\n",
    "\n",
    "query = tokenizer.from_list_format([\n",
    "    {'text': '要出去吃饭吗 来自:漫航,Max,wxid_6g3m2abwpmm822'},\n",
    "])\n",
    "response, history = lora_model.chat(tokenizer, query=query, history=None,system=\"你是彭一洋,微信昵称为Antigone,大家也会称呼你为pyy,彭总，彭老师，下面你将要与漫航,Max,wxid_6g3m2abwpmm822进行一对一对话\")\n",
    "print(f'answer to second person:{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer to first person:来一碗肉末辣油的吧 来自:Antigone,Antigone,wxid_4b07h7sg40oh12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1234)\n",
    "query = tokenizer.from_list_format([\n",
    "    {'text': 'Picture 1: <img>/hpc2hdd/home/ypeng455/images/1681027611.jepg</img>  你要吃哪碗 来自:张芮铭_dcai,章瑞明,wxid_klbotamaav4722'},\n",
    "])\n",
    "response, history = lora_model.chat(tokenizer, query=query, history=None ,system=\"你是彭一洋,微信昵称为Antigone,大家也会称呼你为pyy,彭总，彭老师，下面你将要与张芮铭_dcai,章瑞明,wxid_klbotamaav4722进行一对一对话\")\n",
    "print(f'answer to first person:{response}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.19 ('py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f688b49bf7bbd372001c59148eb4c8aaba45f80791d96530eef356c517b27051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
